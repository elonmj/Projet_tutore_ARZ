

# **Rapport sur l'Optimisation du Trafic Urbain en Afrique de l'Ouest par Jumeau Numérique et Apprentissage par Renforcement**

## **Résumé Exécutif**

Ce rapport présente une approche novatrice pour la gestion du trafic urbain en Afrique de l'Ouest, en se concentrant spécifiquement sur la mégalopole de Lagos. Face aux défis uniques posés par l'hétérogénéité extrême des véhicules, les comportements de conduite adaptatifs et les infrastructures variables, les solutions de gestion de trafic conventionnelles se sont révélées inadaptées. Le projet propose une solution révolutionnaire fondée sur le concept de Jumeau Numérique, une réplique virtuelle haute-fidélité du système de trafic réel, couplée à l'Apprentissage par Renforcement (RL) pour un contrôle adaptatif des feux de signalisation. Cette synergie vise à surmonter les limitations des approches statiques et à optimiser dynamiquement les performances du réseau. L'objectif est de réduire significativement les temps de parcours, d'améliorer la fluidité du trafic, de diminuer les émissions polluantes et de s'adapter en temps réel aux variations de la demande et aux incidents. Le rapport détaille la formalisation du problème en Processus de Décision Markovien (MDP), l'architecture de l'agent de contrôle intelligent, les algorithmes de RL privilégiés, et les stratégies mises en œuvre pour atténuer les défis liés aux limitations des données. Ce travail représente une avancée majeure vers le développement de solutions technologiques endogènes, adaptées aux réalités locales et portées par l'excellence scientifique africaine.

## **1\. Introduction : L'Impératif du Contrôle Intelligent du Trafic en Afrique de l'Ouest**

### **1.1 Contexte Mondial de l'Urbanisation et des Défis du Trafic**

L'Afrique de l'Ouest est confrontée à une urbanisation d'une rapidité sans précédent au XXIe siècle, affichant des taux de croissance urbaine parmi les plus élevés au monde. Cette explosion démographique exerce une pression considérable sur les infrastructures de transport des métropoles régionales telles que Lagos, Accra, Dakar et Cotonou. Lagos, une mégalopole abritant plus de 15 millions d'habitants, illustre parfaitement l'ampleur de cette problématique, où la mobilité urbaine est devenue un enjeu déterminant pour le développement économique, la compétitivité internationale et la qualité de vie des résidents.1

Dans ce contexte, la congestion routière chronique ne constitue plus une simple gêne ; elle représente un obstacle majeur au développement économique. Les pertes économiques attribuables aux embouteillages sont estimées à plusieurs milliards de dollars par an pour la seule région de Lagos. À cela s'ajoutent des impacts sanitaires et environnementaux significatifs, incluant la pollution atmosphérique, le stress et une augmentation des accidents.1 Cette situation confère au problème une dimension qui dépasse le simple défi technique, le transformant en un enjeu critique pour le développement économique et social. L'ampleur des pertes économiques annuelles souligne l'urgence de solutions sur mesure, plutôt que l'adaptation de systèmes génériques, pour débloquer ce goulot d'étranglement fondamental.

### **1.2 Caractéristiques Uniques du Trafic Ouest-Africain (Focus sur Lagos)**

Le trafic urbain en Afrique de l'Ouest se distingue fondamentalement des environnements pour lesquels la plupart des systèmes de gestion intelligente du trafic ont été conçus. Cette spécificité est marquée par une hétérogénéité extrême du parc véhiculaire, où les motocyclettes, souvent majoritaires (parfois plus de 70% du trafic), coexistent avec les voitures particulières, les véhicules commerciaux, les tricycles motorisés et même, par moments, des véhicules non motorisés.1

Les conducteurs, en particulier ceux de deux-roues, adoptent des comportements de conduite adaptatifs. Ces stratégies incluent le « filtrage inter-véhiculaire » où ils se faufilent entre les véhicules, la « remontée de files » pour dépasser les files d'attente aux intersections, et le « creeping », une capacité à maintenir une vitesse résiduelle même en situation de congestion extrême, optimisant ainsi l'utilisation de l'espace disponible.1 En outre, l'infrastructure routière est souvent hétérogène, caractérisée par une qualité variable des routes, une signalisation fréquemment déficiente ou mal synchronisée, et des intersections non régulées. Cette combinaison de facteurs, associée à une saturation chronique où la demande de mobilité dépasse largement la capacité des infrastructures existantes, crée un environnement de trafic d'une complexité et d'une imprévisibilité considérables.1

Face à ces particularités, les solutions de gestion de trafic « standard », conçues pour des contextes plus homogènes et disciplinés, se révèlent « largement inadaptées ou sous-performantes ».1 Cela ne traduit pas une simple inefficacité, mais une inadéquation fondamentale entre les hypothèses sous-jacentes des modèles de trafic traditionnels (tels que la discipline de voie, l'homogénéité des véhicules et la prévisibilité des flux) et les dynamiques observées, souvent informelles, du trafic ouest-africain. Le défi ne consiste donc pas seulement à optimiser des paramètres existants, mais à opérer un changement de paradigme dans la modélisation et le contrôle du trafic, exigeant une approche de fond qui intègre et valorise ces comportements uniques.

### **1.3 La Promesse des Jumeaux Numériques et de l'Apprentissage par Renforcement**

Ce projet propose une approche novatrice, ancrée sur le concept de Jumeau Numérique, perçu comme la « fondation indispensable » pour des stratégies de contrôle intelligent spécifiquement conçues pour le contexte ouest-africain.1 Le Jumeau Numérique est une réplique virtuelle de haute fidélité du système de trafic réel, capable de simuler en temps quasi-réel la dynamique complexe des flux hétérogènes. Cette approche se distingue des modélisations classiques par sa capacité à intégrer la physique spécifique des différentes classes de véhicules, à capturer les phénomènes hors-équilibre tels que l'hystérésis et les ondes de choc, et à modéliser l'impact de la variabilité infrastructurelle sur les comportements de conduite.1

Sur cette base solide, l'Apprentissage par Renforcement (RL) émerge comme la « technologie de rupture » pour le contrôle adaptatif des feux de signalisation. Contrairement aux approches classiques d'optimisation statique, le RL permet de développer des politiques de contrôle qui s'adaptent dynamiquement aux conditions changeantes, apprennent des schémas récurrents et optimisent les performances globales du réseau.1 La vision du projet est de créer un système de contrôle intelligent capable de réduire les temps de parcours d'au moins 20%, d'améliorer la fluidité du trafic en optimisant l'utilisation des infrastructures existantes, de diminuer les émissions polluantes par la réduction des arrêts et redémarrages, et de s'adapter en temps réel aux variations de la demande et aux incidents.1

L'accent mis sur un Jumeau Numérique de haute fidélité et sur des algorithmes avancés de RL révèle une reconnaissance stratégique : aucune de ces composantes n'est suffisante à elle seule pour le contexte ouest-africain. Le Jumeau Numérique fournit l'environnement réaliste et complexe nécessaire au RL pour apprendre efficacement, tandis que le RL apporte l'intelligence adaptative qui fait défaut aux modèles traditionnels. Il s'agit d'une approche synergique où la qualité de la simulation influence directement la performance de la politique apprise. La précision du Jumeau Numérique est un « facteur de succès critique » pour l'agent RL, ce qui signifie que les défis liés à sa construction, tels que les limitations des données pour la calibration, auront des répercussions directes sur les performances de l'agent RL.1 Cela met en évidence un lien de causalité crucial : la qualité et le réalisme de l'apprentissage de l'IA sont directement contraints par la précision de son environnement d'entraînement. Toute imprécision dans la représentation de la complexité du trafic ouest-africain par le Jumeau Numérique, due par exemple à la rareté des données ou à des simplifications de modélisation, se traduira inévitablement par des politiques sous-optimales, voire contre-productives, de la part de l'agent RL. L'investissement dans un Jumeau Numérique de haute fidélité n'est donc pas une simple étape préparatoire, mais un catalyseur continu et essentiel pour un déploiement efficace du RL dans des systèmes réels aussi exigeants.

## **2\. Le Jumeau Numérique : Un Environnement de Simulation Essentiel pour le Trafic Hétérogène**

### **2.1 Fondation dans les Modèles Macroscopiques de Trafic Avancés (ARZ Multi-Classes)**

Le Jumeau Numérique est conçu comme une réplique virtuelle haute-fidélité capable de reproduire la dynamique complexe des flux de trafic hétérogènes en temps quasi-réel.1 Sa conception repose sur des modèles macroscopiques du trafic, en particulier en abordant les limitations des modèles de premier ordre tels que le modèle Lighthill-Whitham-Richards (LWR). Le modèle LWR, bien que simple et robuste, repose sur l'hypothèse d'une relation d'équilibre instantanée entre la vitesse et la densité, et suppose un flux homogène.1 Ces hypothèses sont inadéquates pour le contexte ouest-africain car elles ignorent l'hétérogénéité fondamentale du trafic, ne peuvent pas capturer les phénomènes hors équilibre cruciaux (comme l'hystérésis et les ondes stop-and-go), et négligent l'impact de la qualité variable de l'infrastructure.1

Pour surmonter ces limitations, le projet s'appuie sur sa propre extension du modèle Aw-Rascle-Zhang (ARZ), un modèle de second ordre spécifiquement développé pour le contexte béninois, qui partage de nombreuses caractéristiques de trafic avec Lagos.1 Le modèle ARZ introduit une équation dynamique supplémentaire pour la vitesse, permettant de modéliser l'inertie du flux et les états hors équilibre. Ses principaux atouts incluent le respect de l'anisotropie (les conducteurs réagissent à ce qui se passe devant eux), la capacité à modéliser l'hystérésis et les oscillations stop-and-go, et l'évitement des vitesses négatives non physiques. Il offre également une base flexible pour les extensions multi-classes.1 Le rejet explicite des modèles LWR en raison de leurs « limitations critiques », notamment leur incapacité à modéliser les « phénomènes hors équilibre » comme l'hystérésis et les oscillations stop-and-go, et l'adoption subséquente du modèle ARZ, constituent une décision de conception fondamentale. Cela signifie que le trafic réel, en particulier dans les environnements congestionnés et hétérogènes, est intrinsèquement dynamique et hors équilibre. Un modèle incapable de capturer ces instabilités fausserait fondamentalement le comportement du système, conduisant à des politiques de contrôle qui, bien que théoriquement valables pour un modèle simplifié, seraient inefficaces, voire déstabilisantes, en réalité. Le choix de l'ARZ est donc une décision fondatrice pour garantir la capacité du Jumeau Numérique à simuler les dynamiques complexes et réelles du trafic ouest-africain, ce qui est essentiel pour que l'agent RL puisse apprendre des politiques robustes.

La modélisation multi-classes est considérée comme une « nécessité absolue » pour le contexte ouest-africain. L'approche étend le modèle ARZ avec des équations distinctes pour chaque classe de véhicules (par exemple, motos et autres véhicules) afin de refléter leurs propriétés uniques et leurs interactions.1

### **2.2 Modélisation des Spécificités Ouest-Africaines : Creeping, Gap-Filling et Impact de l'Infrastructure**

Des innovations clés sont intégrées dans l'extension multi-classes du modèle ARZ pour gérer l'hétérogénéité du trafic ouest-africain. Un paramètre $ \alpha < 1 $ est utilisé pour modéliser la perception réduite de la congestion par les motos, capturant ainsi les phénomènes de « gap-filling » (utilisation des espaces entre les véhicules) et d'« interweaving » (mouvements latéraux entre les files).1 Une vitesse de « creeping » (

$ V_{creeping} > 0 $) permet aux motos de maintenir une mobilité résiduelle même en congestion extrême.1 Enfin, une dépendance spatiale

$ R(x) $ est intégrée pour modéliser l'impact de la qualité variable des infrastructures sur les vitesses des véhicules.1

Le document Josaphat\_tutored\_project.pdf 1 fournit des paramètres de base estimés pour ces innovations. La fonction

$ R(x) $ catégorise les routes en 5 types (Majeures, Secondaires, Résidentielles/Locales, Pistes, Chemins/Services), avec des valeurs $ V_{max,i}(R) $ correspondantes. Les motos sont considérées comme moins sensibles à la dégradation des routes, avec des $ V_{max,m} $ plus élevés sur les routes dégradées que les $ V_{max,c} $ pour les voitures.1 Le paramètre

$ \alpha $ est fixé à 0.4, suggérant qu'une voiture contribue à 40% de son impact de densité perçu par les motos.1 La

$ V_{creeping} $ est établie à 5~km/h (environ 1.4~m/s) pour les motos, et 0~km/h pour les voitures.1 Des fonctions de pression (

$ \Pi(x) = K_i \left(\frac{x}{\rho_{jam}}\right)^{\gamma_i} $) et des temps de relaxation ($ \tau_m = 5~s $, $ \tau_c = 10~s $) sont également spécifiés pour refléter les comportements spécifiques à chaque classe et leurs taux d'adaptation.1

Cette intégration détaillée de la complexité dans le Jumeau Numérique est cruciale car elle « transfère une part significative de la charge de 'comprendre l'hétérogénéité' de l'algorithme RL lui-même vers le modèle de simulation fondamental ».1 L'intégration explicite et détaillée de comportements tels que le « creeping », le « gap-filling » et l'« interweaving » dans le modèle ARZ via des paramètres comme

alpha et V\_creeping est une décision de conception profonde. Cela signifie qu'un contrôle efficace du trafic dans ce contexte spécifique ne peut pas se baser sur des hypothèses de conduite formelle et disciplinée. Au lieu de cela, le système doit tenir compte de ces comportements adaptatifs informels, et potentiellement les exploiter. En les modélisant au sein du Jumeau Numérique, l'agent RL peut apprendre des politiques qui sont non seulement robustes face à ces dynamiques uniques, mais qui peuvent également optimiser le flux, par exemple, en gérant intelligemment les phases pour permettre aux motos de « ramper » ou d'utiliser les interstices plus efficacement. Cela déplace le paradigme de contrôle de l'application de règles idéalisées vers l'adaptation et l'optimisation au sein de dynamiques humaines existantes et complexes.

Le Tableau 1 présente les paramètres de base estimés pour le modèle ARZ multi-classes, qui sont essentiels pour la transparence scientifique et la reproductibilité des simulations. Ces valeurs servent de point de départ pour l'analyse de sensibilité et la calibration future, soulignant l'approche innovante du projet pour modéliser l'hétérogénéité du trafic.

**Tableau 1 : Paramètres de base estimés pour le modèle ARZ multi-classes étendu**

| Paramètre/Fonction | Symbole | Valeur/Forme Fonctionnelle de Base |
| :---- | :---- | :---- |
| **Paramètres Comportementaux Moto** |  |  |
| Gap-filling / Interweaving | α | 0.4 |
| Vitesse de Creeping | Vcreeping | 5 km/h (≈ 1.4 m/s) |
| **Paramètres Communs / Environnement** |  |  |
| Densité de Blocage Physique | ρjam | 250 véh/km |
| Composition Flux (Urbain) | (%m / %c) | 75% / 25% |
| Composition Flux (Interurbain) | (%m / %c) | 50% / 50% |
| **Fonctions de Pression** | $ \pi = \Pi(x) = K_i \left(\frac{x}{\rho_{jam}}\right)^{\gamma_i} $ |  |
| Argument Pression Motos | x pour $ P_m $ | $ \rho_{eff,m} = \rho_m + \alpha \rho_c $ |
| Argument Pression Voitures | x pour $ P_c $ | $ \rho = \rho_m + \rho_c $ |
| Exposant Pression Motos | γm | 1.5 |
| Exposant Pression Voitures | γc | 2.0 |
| Constante Pression Motos | Km | 10 km/h |
| Constante Pression Voitures | Kc | 15 km/h |
| **Vitesse Max. Flux Libre (km/h)** |  |  |
| R=1 (Majeures) | Vmax,c(1)/Vmax,m(1) | 75 / 85 |
| R=2 (Secondaires) | Vmax,c(2)/Vmax,m(2) | 60 / 70 |
| R=3 (Locales) | Vmax,c(3)/Vmax,m(3) | 35 / 50 |
| R=4 (Pistes) | Vmax,c(4)/Vmax,m(4) | 25 / 45 |
| R=5 (Chemins/Service) | Vmax,c(5)/Vmax,m(5) | 10 / 30 |
| R=9 (Inconnu) | Vmax,c(9)/Vmax,m(9) | 35 / 50 |
| **Fonctions Vitesse Équilibre** |  |  |
| Forme générale Motos $ V_{e,m} $ |  | $ V_{creeping} + (V_{max,m}(R) - V_{creeping}) (1 - \frac{\rho}{\rho_{jam}})_+ $ |
| Forme générale Voitures $ V_{e,c} $ |  | $ V_{max,c}(R) (1 - \frac{\rho}{\rho_{jam}})_+ $ |
| Fonction de réduction ($ g_i $) |  | $ (1 - \frac{\rho}{\rho_{jam}})_+ $ |
| **Temps de Relaxation** |  |  |
| Motos | τm | 5 secondes (≈ 0.0014 h) |
| Voitures | τc | 10 secondes (≈ 0.0028 h) |

Source: 1

## **3\. Formalisation du Problème de Contrôle du Trafic comme un Processus de Décision Markovien (MDP)**

Le problème de contrôle des feux de signalisation est rigoureusement formalisé comme un Processus de Décision Markovien (MDP), ce qui est essentiel pour l'application de l'apprentissage par renforcement. Cette formalisation exige une définition précise de ses composants fondamentaux : l'espace d'état, l'espace d'action et la fonction de récompense.1

### **3.1 Définition de l'Espace d'État (S) pour le Trafic Multi-Classes**

L'espace d'état S est un vecteur de dimension d'environ 50, englobant des informations détaillées sur l'état du trafic à un instant t donné.1 Les éléments clés de ce vecteur incluent les densités et les vitesses par classe de véhicule pour chaque segment de route, les longueurs des files d'attente par direction aux intersections, les états actuels des feux de signalisation (phase, temps écoulé), et un historique à court terme (3 à 5 pas de temps précédents) pour capturer la dynamique temporelle.1

L'intégration des « densités et vitesses par classe de véhicule » dans l'espace d'état représente une réponse directe et essentielle à l'hétérogénéité extrême du trafic ouest-africain. Ce choix de conception permet à l'agent RL de disposer d'informations granulaires et spécifiques au contexte, lui permettant ainsi d'élaborer des politiques qui différencient le contrôle en fonction de la composition des véhicules, plutôt que de traiter l'ensemble du trafic comme une entité homogène.1 Cependant, cette granularité contribue de manière significative à ce qui est connu sous le nom de « malédiction de la dimensionnalité », rendant l'espace d'état vaste et complexe. Cette complexité accrue peut remettre en question la stabilité de l'algorithme et l'efficacité de l'apprentissage.1 La décision de concevoir un espace d'état riche en informations sur les classes de véhicules met en lumière un compromis fondamental en ingénierie et en science : si une granularité élevée est souhaitable pour une modélisation et un contrôle précis, elle augmente de manière exponentielle la complexité du problème d'apprentissage, pouvant le rendre intraitables sur le plan computationnel ou entraîner une instabilité de l'apprentissage. Cela implique que le projet doit constamment équilibrer le désir d'une représentation réaliste avec les contraintes pratiques de faisabilité computationnelle, ce qui pourrait nécessiter des recherches futures sur la réduction de la dimensionnalité ou des représentations d'état plus abstraites.

### **3.2 Conception de l'Espace d'Action Discret (A) pour le Contrôle des Feux**

L'espace d'action A est constitué d'actions discrètes pour chaque intersection.1 Ces actions comprennent l'extension ou la réduction de la phase courante (par incréments de ±5s ou ±10s), l'activation d'une phase prioritaire pour une direction saturée, ou le maintien du cycle normal.1

Le choix d'un espace d'action discret, avec des ajustements de temps spécifiques et l'activation de phases prioritaires, établit un équilibre entre la granularité du contrôle et la faisabilité pratique de la mise en œuvre. Cette approche simplifie le problème d'apprentissage par renforcement (par exemple, en permettant des méthodes basées sur la valeur comme DQN) et s'aligne mieux avec les contraintes opérationnelles typiques des contrôleurs de feux de signalisation existants.1 Cela permet d'éviter les complexités associées aux espaces d'action continus, qui sont souvent plus difficiles à apprendre de manière efficace et stable pour les algorithmes d'apprentissage par renforcement.1 La décision d'utiliser un espace d'action discret, avec des ajustements de phase prédéfinis et incrémentaux, est une approche pragmatique. Bien que les espaces d'action continus puissent offrir un contrôle théoriquement plus fin, ils introduisent des complexités significatives pour les algorithmes de RL, entraînant souvent une convergence plus lente ou une instabilité. Ce choix reconnaît implicitement les contraintes réelles du matériel de signalisation routière existant et des protocoles opérationnels. Il garantit que les politiques apprises sont non seulement efficaces mais aussi directement implémentables et gérables dans les limites des infrastructures actuelles, privilégiant la déployabilité et la stabilité de l'apprentissage par rapport à une flexibilité théorique maximale. Cela influence également la pertinence de divers algorithmes de RL, favorisant ceux qui sont robustes avec des ensembles d'actions discrètes.

### **3.3 Élaboration de la Fonction de Récompense Multi-Objectifs (R)**

La fonction de récompense R(s, a, s') est une combinaison pondérée de plusieurs métriques de performance.1 La formule de la récompense est donnée par :

$$
R = -w_1 \cdot TT - w_2 \cdot TW + w_3 \cdot THR - w_4 \cdot TP
$$
.1

Les composantes de cette fonction de récompense sont :

* TT (Temps de Parcours Total) : avec un poids négatif pour minimiser.  
* TW (Temps d'Attente Moyen) : avec un poids négatif pour minimiser.  
* THR (Débit Total) : avec un poids positif pour maximiser le débit.  
* TP (Pénalité pour les changements fréquents de phases de feux de signalisation) : avec un poids négatif pour minimiser les changements fréquents et favoriser la stabilité.1

La nature multi-objectifs de la fonction de récompense, qui vise à minimiser le temps de parcours et le temps d'attente, à maximiser le débit et à pénaliser les changements fréquents, constitue un choix de conception sophistiqué. Elle reflète la compréhension qu'une gestion optimale du trafic exige un équilibre entre des objectifs parfois contradictoires (par exemple, maximiser le flux tout en assurant l'équité, ou l'efficacité tout en maintenant la stabilité). L'inclusion d'une pénalité pour les changements fréquents est particulièrement pertinente, car elle aborde directement la préoccupation pratique du « bégaiement » ou de l'instabilité du contrôle, qui peut dégrader les performances du système et l'expérience utilisateur.1 Cela démontre une approche holistique de la définition d'un « bon » contrôle du trafic dans le contexte ouest-africain. La fonction de récompense multi-objectifs, en équilibrant ces différentes métriques, est plus qu'une simple formule technique ; elle est un choix de conception essentiel qui encode explicitement la définition du projet d'un contrôle de trafic « optimal ». Cela implique une compréhension sophistiquée du fait qu'optimiser une seule métrique (par exemple, uniquement le débit) pourrait entraîner des comportements indésirables du système (par exemple, des temps d'attente excessifs pour certaines directions ou des changements de signal instables qui frustrent les conducteurs). La pénalité explicite pour les changements de phase fréquents aborde directement une préoccupation opérationnelle pratique qui affecte l'expérience utilisateur et la fiabilité du système, même si cela pourrait légèrement réduire le débit théorique. Cela illustre une approche globale de la définition de la gestion optimale du trafic, alignant les objectifs d'apprentissage de l'IA avec des valeurs sociétales et opérationnelles complexes du monde réel.

Le Tableau 2 synthétise la formalisation du problème d'apprentissage par renforcement, offrant une vue d'ensemble claire des principaux composants du MDP.

**Tableau 2 : Formalisation du problème de contrôle du trafic en MDP**

| Composant | Description |
| :---- | :---- |
| **État (S)** | Vecteur d'environ 50 dimensions incluant densités et vitesses par classe de véhicule pour chaque segment de route, longueurs des files d'attente par direction aux intersections, états actuels des feux (phase, temps écoulé), historique à court terme (3-5 pas de temps précédents). |
| **Action (A)** | Actions discrètes pour chaque intersection: extension/réduction de la phase courante (±5s, ±10s), activation de phase prioritaire pour direction saturée, maintien du cycle normal. |
| **Récompense ($ R(s,a,s') $)** | Combinaison pondérée : $ R = -w_1 \cdot TT - w_2 \cdot TW + w_3 \cdot THR - w_4 \cdot TP $ (où $ TT $ = temps de parcours total, $ TW $ = temps d'attente moyen, $ THR $ = débit total, $ TP $ = pénalité changements fréquents). |

Source: 1

## **4\. Architecture de l'Agent de Contrôle Intelligent : Des Paradigmes Centralisés aux Multi-Agents**

### **4.1 Architecture Centralisée Coordonnée pour les Corridors Pilotes : Avantages et Portée**

Le protocole de recherche adopte initialement une architecture « centralisée coordonnée », où un agent unique est chargé de contrôler l'ensemble des intersections au sein d'un corridor défini.1 Cette approche est justifiée par sa capacité à permettre une « optimisation globale tout en maintenant la tractabilité computationnelle ».1 Le champ d'application initial de cette architecture est délibérément limité à un corridor stratégique de 2 à 3 km, comprenant 3 à 4 intersections majeures à Lagos.1

Cette décision représente un « compromis pragmatique ».1 Le contrôle centralisé offre l'avantage d'une optimisation globale et permet d'éviter les complexités liées à la communication inter-agents et à la non-stationnarité inhérentes aux systèmes multi-agents. Ce choix priorise la tractabilité initiale et l'optimalité globale pour un segment gérable, reconnaissant qu'une application régionale plus large pourrait exiger un changement de paradigme architectural.1 Le choix explicite du projet de commencer par une architecture « centralisée coordonnée » pour un « corridor limité », qualifié de « compromis pragmatique », révèle une stratégie sophistiquée de gestion de la complexité inhérente au système. Cela implique une décision délibérée d'établir une base robuste et de valider les concepts fondamentaux au sein d'un système plus simple et plus gérable avant de tenter une mise à l'échelle. S'orienter directement vers un système d'apprentissage par renforcement multi-agents (MARL) à grande échelle introduirait trop de défis simultanés (par exemple, observabilité partielle, non-stationnarité, coordination complexe), augmentant considérablement le risque du projet. Cette approche échelonnée permet un apprentissage incrémental, une atténuation des risques et l'accumulation de connaissances fondamentales qui peuvent éclairer les futures expansions plus ambitieuses.

### **4.2 Limitations pour les Réseaux Massifs et l'Avenir de l'Apprentissage par Renforcement Multi-Agents (MARL)**

Bien que l'architecture centralisée soit avantageuse pour une portée limitée, elle est intrinsèquement confrontée à des « limitations de mise à l'échelle pour les réseaux 'massifs' ».1 L'apprentissage par renforcement multi-agents (MARL) est identifié comme une « approche prometteuse » pour étendre le contrôle des feux de signalisation à des réseaux plus vastes et plus complexes, en distribuant le contrôle global à des agents RL locaux.1

Le MARL offre plusieurs avantages : il peut gérer l'hétérogénéité des configurations d'intersection (où les connaissances ne sont pas directement réutilisables d'une intersection à l'autre), offre une plus grande résilience, permet une adaptation localisée aux caractéristiques uniques des intersections et offre une meilleure évolutivité pour un déploiement à l'échelle de la ville ou de la région.1 Des exemples d'approches MARL incluent l'Independent Q-Learning (IQL) ou l'Independent Deep Q-Network (IDQN), où chaque agent apprend sa propre politique indépendamment (bien que cela puisse souffrir de non-stationnarité), ainsi que des méthodes coopératives plus avancées comme Actor-Attention-Critic (MAAC-TLC) et Multi-Agent Soft Actor-Critic (MA-SAC) pour une communication et une optimisation collective efficaces.1

Cependant, le MARL présente des défis importants, notamment l'observabilité partielle (chaque agent local n'ayant qu'une vue limitée de l'environnement), la non-stationnarité (l'environnement du point de vue d'un agent individuel change à mesure que d'autres agents apprennent et mettent à jour leurs politiques), et la complexité des mécanismes de coordination.1 L'objectif à long terme du projet d'« extensibilité régionale » suggère fortement que le MARL sera une « évolution nécessaire » par rapport à l'architecture centralisée initiale.1 La reconnaissance explicite que le contrôle centralisé présente des « limitations de mise à l'échelle pour les réseaux 'massifs' » et que le MARL « sera une évolution nécessaire » pour l'« extensibilité régionale » révèle une feuille de route architecturale claire et prospective. Cela implique que le projet comprend les limites fondamentales d'un agent de contrôle unique et monolithique pour gérer les réseaux de trafic vastes, dynamiques et hétérogènes d'une ville ou d'une région entière. La transition vers le MARL n'est pas seulement une amélioration optionnelle, mais un impératif stratégique pour atteindre la vision plus large du projet d'un impact généralisé. Cette prévoyance positionne le projet pour relever les défis futurs de manière proactive, nécessitant une recherche continue sur les complexités inhérentes au MARL, telles que la non-stationnarité et la coordination.

## **5\. Approfondissement des Algorithmes d'Apprentissage par Renforcement pour le Contrôle des Feux de Signalisation**

Cette section analyse les principaux algorithmes d'apprentissage par renforcement (RL), évaluant leur pertinence pour le contexte du trafic ouest-africain, en tenant compte du MDP défini et des choix architecturaux.

### **5.1 Choix Initial : Deep Q-Networks (DQN) et ses Variantes (Double DQN, Dueling DQN)**

Le projet privilégie initialement l'algorithme Deep Q-Network (DQN) ainsi que ses extensions, Double DQN et Dueling DQN.1 Le DQN combine l'apprentissage Q avec des réseaux neuronaux profonds pour gérer efficacement de grands espaces d'état et apprendre des stratégies de contrôle optimales par interaction continue avec l'environnement.1

Les avantages cités pour ce choix initial incluent leur « performance démontrée dans le contrôle de trafic multi-intersection », leur capacité à gérer des espaces d'état de grande dimension, et une stabilité d'apprentissage améliorée grâce à Double DQN (qui réduit la surestimation des valeurs Q) et Dueling DQN (qui découple les fonctions de valeur et d'avantage pour un apprentissage plus rapide). Ces algorithmes peuvent également être intégrés au simulateur ARZ multi-classes du projet.1 Les limitations reconnues incluent leur conception principale pour des espaces d'action discrets (ce qui est en accord avec la définition de l'espace d'action du projet) et leur potentiel d'inefficacité en termes d'échantillonnage en tant qu'algorithmes sans modèle, nécessitant une interaction étendue avec l'environnement.1

Le choix initial est justifié comme une « décision stratégiquement judicieuse pour une phase de fondation », fournissant une base robuste pour les performances par rapport à laquelle des algorithmes plus avancés pourront être comparés ultérieurement.1 La sélection initiale de DQN et de ses variantes, justifiée par leur « stabilité éprouvée » et leur « performance démontrée », témoigne d'une philosophie d'ingénierie pragmatique. Dans une application complexe du monde réel comme le contrôle du trafic en Afrique de l'Ouest, caractérisée par une forte stochasticité et des limitations de données, il est crucial de privilégier des algorithmes bien compris, fiables et capables de fournir une performance de base solide. Cette approche suggère que la construction d'une fondation stable et implémentable est plus critique dans la phase initiale que la recherche de gains de performance marginaux avec des algorithmes plus expérimentaux ou exigeants en calcul. Cela permet à l'équipe d'établir un système fonctionnel et de recueillir des informations initiales avant de s'attaquer à des optimisations plus avancées.

### **5.2 Exploration Future : Méthodes de Gradient de Politique (PPO) et Approches Acteur-Critique (SAC)**

Le projet prévoit d'explorer d'autres algorithmes, tels que Proximal Policy Optimization (PPO) et Soft Actor-Critic (SAC), pour les itérations futures afin d'assurer la robustesse et l'adaptabilité du système.1

Le PPO est une méthode de gradient de politique reconnue pour équilibrer performance, efficacité d'échantillonnage et simplicité. Son « objectif de substitution rogné » empêche les mises à jour importantes de la politique, assurant ainsi la stabilité et évitant les résultats catastrophiques, ce qui le rend robuste dans des environnements dynamiques et chaotiques. Il offre également une efficacité d'échantillonnage grâce à la réutilisation des expériences collectées et convient aux domaines continus et discrets.1 La stabilité du PPO est particulièrement pertinente pour le trafic ouest-africain, caractérisé par des comportements de conduite adaptatifs et une saturation chronique, qui créent des flux de trafic très dynamiques et potentiellement chaotiques. La stabilité inhérente du PPO pourrait être cruciale pour maintenir les performances de contrôle dans des conditions extrêmes et imprévisibles, soutenant directement l'hypothèse de robustesse du projet. Son efficacité d'échantillonnage est également un avantage significatif compte tenu des limitations potentielles des données.1

Le SAC est un algorithme acteur-critique hors-politique qui optimise une politique stochastique. Ses caractéristiques clés incluent la « régularisation de l'entropie », qui encourage l'exploration et prévient la convergence prématurée vers des optima locaux sous-optimaux, ce qui est crucial dans les dynamiques de trafic complexes et non linéaires. Sa nature hors-politique améliore également l'efficacité d'échantillonnage et la stabilité.1 L'intégration unique de la régularisation de l'entropie par le SAC constitue un avantage significatif pour l'apprentissage dans des environnements de trafic complexes et potentiellement trompeurs. En encourageant explicitement l'exploration, le SAC peut empêcher l'agent de converger prématurément vers des optima locaux sous-optimaux, ce qui représente un risque dans des environnements aux dynamiques très non linéaires comme le trafic hétérogène. Sa nature hors-politique et sa grande efficacité d'échantillonnage offrent également des avantages pratiques, réduisant le besoin de simulations coûteuses et étendues, ce qui s'aligne avec les défis de données du projet.1 L'exploration future du PPO et du SAC, justifiée par leurs forces respectives en matière de stabilité, d'efficacité d'échantillonnage et d'exploration, révèle une approche proactive de la sélection algorithmique. Cela indique une reconnaissance du fait que le choix initial de DQN, bien que robuste pour les travaux fondamentaux, pourrait ne pas suffire pour tous les défis futurs, en particulier à mesure que le système évolue ou rencontre une stochasticité et une non-linéarité plus extrêmes inhérentes au trafic ouest-africain. La stabilité du PPO répond aux dynamiques chaotiques, tandis que les capacités d'exploration du SAC atténuent le risque d'optima locaux. Cette progression algorithmique structurée démontre une compréhension de la nécessité d'adapter la solution aux conditions du monde réel de plus en plus complexes, chaque choix algorithmique répondant à des limites spécifiques de son prédécesseur.

### **5.3 Apprentissage par Renforcement Basé sur un Modèle (MBRL) : Atténuation des Limitations des Données**

L'apprentissage par renforcement basé sur un modèle (MBRL) est présenté comme une approche cruciale où un agent apprend d'abord un modèle de la dynamique de l'environnement (un « modèle d'inférence de trafic »), puis utilise ce modèle pour réduire les interactions avec l'environnement réel.1

Les avantages du MBRL incluent une efficacité des données considérablement accrue (grâce à la génération de données synthétiques), ce qui réduit le besoin d'essais-erreurs coûteux dans le monde réel. Il accélère l'amélioration de la stratégie, minimise les interactions risquées entre l'agent et l'environnement réel (où les erreurs peuvent provoquer une congestion réelle) et offre des capacités de généralisation pour différents scénarios de trafic.1 Le MBRL est très pertinent pour le contexte ouest-africain, car il aborde directement les « Limitations et Défis des Données API », tels que l'absence de différenciation par classe de véhicule, la granularité spatiale limitée et la latence des données. Le modèle d'inférence du trafic pourrait, par exemple, estimer la composition multi-classes à partir de données agrégées.1

Le MBRL offre une solution convaincante aux limitations inhérentes des données et au coût élevé de l'expérimentation en temps réel dans le contexte ouest-africain, ce qui en fait une approche « très pratique et potentiellement transformative » pour ce projet.1 L'accent mis par le projet sur l'apprentissage par renforcement basé sur un modèle (MBRL) comme solution aux « limitations inhérentes aux données en Afrique de l'Ouest » et au « coût de trial and error très cher » est une orientation stratégique essentielle. Cela signifie que dans des environnements où les données sont rares ou bruitées, les approches traditionnelles de RL sans modèle, qui nécessitent de vastes quantités d'interactions avec le monde réel, sont irréalisables. Le MBRL transforme le problème d'une acquisition directe de données (difficile) en un apprentissage d'un modèle interne, qui peut ensuite générer des données synthétiques pour un entraînement efficace. Il s'agit d'une adaptation cruciale pour le déploiement de l'IA dans des contextes où l'expérimentation en temps réel est soit prohibitivement coûteuse, dangereuse, soit tout simplement impossible, faisant du MBRL une approche « transformative » pour le projet.

Le Tableau 3 présente une analyse comparative structurée des algorithmes d'apprentissage par renforcement, évaluant leurs forces et faiblesses par rapport aux défis spécifiques du trafic ouest-africain.

**Tableau 3 : Analyse comparative des algorithmes d'apprentissage par renforcement pour le contrôle des feux de signalisation**

| Caractéristique | DQN (Double, Dueling) | PPO | SAC | MBRL | MARL (Général) |
| :---- | :---- | :---- | :---- | :---- | :---- |
| **Type d'apprentissage** | Hors-politique, sans modèle | Sur-politique, sans modèle | Hors-politique, sans modèle | Sur/Hors-politique, basé sur modèle | Sur/Hors-politique, sans/avec modèle |
| **Espace d'action** | Discret | Discret/Continu | Discret/Continu (avec variantes) | Discret/Continu | Discret/Continu |
| **Exploration** | epsilon-greedy, Replay Buffer | Clipped Surrogate Objective | Régularisation d'entropie | Basée sur le modèle appris | Coordonnée/Indépendante |
| **Adapté trafic hétérogène** | Oui, via représentation d'état multi-classes | Oui, via représentation d'état multi-classes | Oui, via représentation d'état multi-classes | Oui, via modèle d'inférence | Oui, agents hétérogènes |
| **Évolutivité (Corridor 3-4 intersections)** | Très bonne pour centralisé | Bonne | Bonne | Bonne | Potentiel pour décentralisé |
| **Stabilité** | Améliorée par Double/Dueling DQN | Très bonne, évite les grandes mises à jour | Très bonne, via double critique et entropie | Dépend de la précision du modèle | Dépend de la coordination et non-stationnarité |
| **Efficacité des données** | Faible à modérée | Modérée à bonne | Élevée | Très élevée, réduit les interactions réelles | Variable, dépend de la communication |
| **Exigences de calcul** | Modérées | Modérées à élevées | Élevées | Élevées (pour l'apprentissage du modèle) | Très élevées pour centralisé, variable pour décentralisé |
| **Avantages pour le projet** | Alignement avec MDP défini, stabilité prouvée, intégration existante | Robustesse en environnement dynamique, efficacité d'échantillonnage, stabilité | Meilleure exploration, efficacité d'échantillonnage, stabilité | Atténue les limites des données API, généralisation | Évolutivité régionale future, adaptation locale |
| **Limitations/Défis pour le projet** | Dépendance aux données réelles, potentiel d'instabilité résiduel | Complexité de l'implémentation, tuning des hyperparamètres | Complexité de l'implémentation, tuning des hyperparamètres | Complexité de la construction et calibration du modèle | Non-stationnarité, coordination, observabilité partielle |

Source: 1

## **6\. Gérer les Limitations des Données et Assurer la Robustesse du Système**

### **6.1 Défis Majeurs : Rareté et Incertitude des Données API**

Le projet reconnaît explicitement les « limitations intrinsèques des API de trafic » commerciales telles que TomTom, Google Maps et HERE.1 Ces limitations incluent l'absence de différenciation par classe de véhicule, une granularité spatiale limitée, la latence des données, une couverture incomplète et des biais algorithmiques inhérents.1

Ces contraintes imposent une « révision de la tolérance d'erreur pour la validation du modèle (par exemple, jusqu'à 20%) » et un déplacement de l'accent vers la « validation des tendances plutôt que des valeurs absolues ».1 Le document

Josaphat\_tutored\_project.pdf 1 confirme en outre la rareté des données de trafic pour le Bénin, affirmant que « l'obtention de ce type de données granulaires et continues... représente un défi majeur », ce qui a nécessité l'utilisation de « paramètres estimés » pour le modèle actuel.1 La déclaration explicite selon laquelle les limitations des données API nécessitent une « révision de la tolérance d'erreur... jusqu'à 20 % et un accent sur la validation des tendances plutôt que des valeurs absolues » représente un changement philosophique et méthodologique profond. Cela implique que dans des contextes où les données sont imparfaites ou incomplètes, la recherche d'une précision numérique parfaite pourrait être impossible ou prohibitivement coûteuse. Au lieu de cela, l'accent est mis sur la garantie que le modèle capture avec précision le comportement qualitatif et les tendances générales du système. Cette acceptation pragmatique de l'incertitude des données est un élément clé pour le déploiement de l'IA dans des environnements réels difficiles, où des solutions « suffisamment bonnes » qui saisissent l'essence des dynamiques peuvent néanmoins produire des améliorations pratiques significatives.

### **6.2 Stratégies d'Atténuation : Fusion Multi-Sources, Modèles d'Inférence et Calibration Indirecte**

Pour atténuer les défis liés aux données, plusieurs stratégies sont mises en œuvre. La « fusion multi-sources » combine les données de diverses API (TomTom, Google Maps, HERE) afin d'améliorer la robustesse et la couverture.1 Des « modèles d'inférence » sont développés, utilisant des méthodes statistiques, telles que les réseaux de neurones, pour estimer la composition multi-classes du trafic à partir de données agrégées.1 Une « calibration indirecte » est également envisagée, utilisant des relations empiriques vitesse-densité spécifiques au contexte local pour inférer les paramètres du modèle.1 La validation combine une validation statistique sur de longues périodes avec des observations ponctuelles ciblées sur le terrain.1

Cette approche proactive, qui implique une ingénierie des données sophistiquée et une inférence statistique, est jugée « cruciale » pour la construction d'un Jumeau Numérique de haute fidélité malgré des données d'entrée imparfaites.1 La mise en œuvre active de « stratégies » telles que la « fusion multi-sources » et les « modèles d'inférence statistique » n'est pas un simple détail technique, mais un impératif stratégique. Cela implique une compréhension sophistiquée du fait que les données brutes directement observables sont insuffisantes pour le Jumeau Numérique de haute fidélité requis. Le projet intègre de l'intelligence dans son pipeline de données pour inférer des informations non observées mais critiques (comme la composition multi-classes) à partir de sources disponibles et imparfaites. Cela est essentiel pour les applications d'IA dans les régions en développement, où l'infrastructure de données est souvent naissante. Le succès dépend non seulement d'algorithmes avancés, mais aussi d'une ingénierie des données et d'une inférence statistique innovantes pour combler le fossé entre les données disponibles et les informations riches nécessaires à une modélisation robuste et spécifique au contexte.

### **6.3 Importance de la Robustesse et de la Généralisation dans les Scénarios Réels**

La « convergence stable d'un agent RL dans un environnement stochastique multi-classe » est identifiée comme un « verrou scientifique » clé.1 Le système doit maintenir ses performances (dégradation inférieure à 10%) face à des variations significatives de la demande (par exemple, \+/- 30%) et à des événements perturbateurs tels que des incidents ou des travaux routiers.1 La méthodologie devrait être adaptable à d'autres contextes ouest-africains similaires (par exemple, Accra, Dakar, Cotonou) avec seulement des ajustements paramétriques mineurs (moins de 20% des paramètres).1

Des algorithmes comme Double DQN, Dueling DQN, PPO et SAC sont choisis pour leur stabilité inhérente, tandis que l'apprentissage par renforcement basé sur un modèle (MBRL) offre des capacités de généralisation explicites.1 Le projet définit explicitement le succès non seulement par des performances optimales dans des simulations contrôlées, mais aussi par la capacité du système à maintenir ses performances « face à des variations significatives de la demande... et à des événements perturbateurs » et par son « extensibilité régionale ». Cela implique une compréhension approfondie du fait que le trafic réel est intrinsèquement dynamique, imprévisible et diversifié. Une solution qui ne fonctionne bien que dans des conditions idéales et statiques est pratiquement inutile. Par conséquent, la véritable valeur et l'impact sociétal du système d'IA résident dans sa généralisation à des scénarios inédits et sa robustesse face aux perturbations du monde réel. Cela élève ces qualités de caractéristiques souhaitables à des exigences fondamentales pour un déploiement pratique, distinguant ce projet des exercices purement académiques.

## **7\. Implications Stratégiques et Enseignements Clés**

### **7.1 Comment le Modèle Capture les Dynamiques Uniques du Trafic Ouest-Africain**

Le modèle ARZ multi-classes, avec ses extensions spécifiques, parvient à capturer avec succès les caractéristiques uniques du trafic ouest-africain. Le paramètre alpha modélise efficacement la manière dont les motos perçoivent et naviguent dans la congestion (gap-filling, interweaving), tandis que V\_creeping simule avec précision leur capacité à maintenir une vitesse résiduelle dans un trafic extrême. La fonction R(x) prend en compte l'impact différentiel d'une infrastructure hétérogène sur les différentes classes de véhicules.1

La simulation du scénario « Route Dégradée » valide qualitativement la capacité du modèle à prédire une réduction de vitesse significativement plus importante pour les voitures que pour les motos lors de la rencontre d'une route de mauvaise qualité, ce qui correspond aux observations réelles.1 Le scénario « Feu Rouge / Congestion » démontre la capacité du modèle à reproduire le phénomène de « creeping », où les motos continuent de se déplacer lentement tandis que les voitures sont pratiquement à l'arrêt dans la congestion, un trait distinctif du trafic à Lagos. La nécessité de temps de relaxation courts (

$ \tau_i $) dans ces simulations suggère la nature très réactive et dynamique du trafic ouest-africain.1

La simulation réussie du « creeping » et la nécessité de « temps de relaxation (τi) très courts » pour une propagation réaliste des ondes de choc révèlent une compréhension plus profonde : les comportements uniques des conducteurs ouest-africains (en particulier les motocyclistes) ne sont pas de simples caractéristiques superficielles, mais modifient fondamentalement la dynamique macroscopique de la congestion. La capacité des motos à « ramper » signifie que la « congestion au Bénin n'est peut-être pas un arrêt total mais un écoulement très lent et hétérogène ». Cela implique que les métriques ou modèles de congestion traditionnels (par exemple, l'arrêt total) pourraient être imprécis, et qu'une gestion efficace nécessite de comprendre et de modéliser ce type spécifique de flux lent et hétérogène. Cela a des implications directes pour la planification urbaine, les services d'urgence et les évaluations d'impact économique, car cela modifie la perception et la gestion de la congestion.

### **7.2 Le Rôle Synergique des Jumeaux Numériques et de l'Apprentissage par Renforcement**

Le Jumeau Numérique offre un environnement sûr, reproductible et de haute fidélité pour que l'agent RL puisse apprendre des politiques de contrôle complexes et adaptatives par essais et erreurs intensifs, sans encourir les risques ou les coûts associés à l'expérimentation dans le monde réel (par exemple, la provocation de congestion réelle).1

L'apprentissage par renforcement exploite le réalisme du Jumeau Numérique et sa modélisation détaillée des spécificités ouest-africaines pour apprendre des politiques spécifiquement adaptées au contexte local, allant au-delà des solutions génériques. La capacité du Jumeau Numérique à modéliser les phénomènes hors équilibre permet à l'agent RL d'apprendre à partir et de gérer efficacement les états de trafic dynamiques (par exemple, les ondes de choc, l'hystérésis et la formation/dissipation rapide des files d'attente).1 Le projet met l'accent sur le Jumeau Numérique comme une « fondation indispensable » et souligne que le RL apprend par « interaction continue avec cet environnement ». Cela signifie que le Jumeau Numérique n'est pas seulement un outil de simulation, mais un « terrain d'entraînement » essentiel pour l'IA. Dans un environnement de trafic réel caractérisé par une « imprévisibilité considérable » et potentiellement « chaotique », où « les erreurs peuvent provoquer une congestion réelle », le Jumeau Numérique offre une plateforme sûre, reproductible et évolutive pour que l'agent RL puisse apprendre par essais et erreurs. Cela est crucial pour développer des politiques robustes sans risquer de perturbations ou de dommages dans le monde réel, ce qui en fait un catalyseur essentiel pour le déploiement de l'IA dans les infrastructures publiques à enjeux élevés.

### **7.3 Potentiel d'Impact Quantitatif et de Bénéfices Sociétaux**

Le projet se fixe des objectifs quantitatifs ambitieux : une réduction attendue de 20 à 30% du temps de parcours moyen et une amélioration de 15 à 25% du débit total.1

Au-delà de ses contributions scientifiques, ce travail recèle un « immense potentiel sociétal et économique » pour les villes d'Afrique de l'Ouest, promettant de réduire les coûts de la congestion, d'améliorer la qualité de l'environnement et d'accroître la qualité de vie des populations.1 Cette initiative représente une « étape significative vers le développement de solutions technologiques endogènes, adaptées aux réalités locales, et portées par l'excellence scientifique africaine dans les domaines de pointe de la modélisation mathématique et de l'intelligence artificielle ».1 Le positionnement explicite du projet comme une « étape significative vers le développement de solutions technologiques endogènes, adaptées aux réalités locales, et portées par l'excellence scientifique africaine » élève le projet au-delà d'une simple solution technique pour en faire une initiative stratégique plus large. Cela implique que le projet ne résout pas seulement un problème de trafic, mais qu'il est également un modèle de la manière dont les nations africaines peuvent développer leurs propres solutions de haute technologie adaptées à leurs défis uniques, réduisant ainsi la dépendance à l'égard de technologies importées, souvent inadaptées. Cela positionne le projet comme un leader potentiel dans l'IA pour le développement, démontrant une voie pour d'autres régions confrontées à des défis similaires et favorisant les capacités scientifiques et technologiques locales.

## **8\. Orientations Futures et Recommandations**

### **8.1 Collecte de Données et Validation Quantitative**

La « Priorité Absolue » pour les recherches futures est la collecte de données réelles (vitesses, débits, densités par classe via caméras/analyse vidéo) sur différents types de routes et conditions de trafic au Bénin.1 Ces données sont essentielles pour calibrer rigoureusement les paramètres du modèle (par exemple,

alpha, V\_creeping, Ki, gamma\_i, tau\_i) et valider quantitativement ses prédictions.1

Le modèle actuel repose sur des « paramètres estimés » en raison de la rareté des données, ce qui est reconnu comme une « Limite Majeure » affectant sa capacité prédictive quantitative actuelle.1 La reconnaissance répétée de la dépendance actuelle à des « paramètres estimés » et la classification de l'« Absence de Calibration/Validation Quantitative » comme une « Limite Majeure » mettent en évidence une boucle de rétroaction cruciale. Bien que le modèle actuel soit phénoménologiquement plausible, sa véritable puissance prédictive et sa capacité à éclairer les politiques dépendent des données du monde réel. La « Priorité Absolue » pour les travaux futurs souligne que le succès à long terme du projet n'est pas uniquement algorithmique, mais profondément lié au développement d'une infrastructure et de méthodologies de collecte de données locales robustes. Cela implique que l'évolution du projet seraT guidée par un processus itératif d'acquisition de données, de raffinement du modèle et de validation quantitative, comblant continuellement le fossé entre la modélisation théorique et la réalité empirique.

### **8.2 Implémentations Numériques Avancées et Raffinements du Modèle**

Les travaux futurs devraient se concentrer sur l'implémentation de schémas numériques d'ordre supérieur (par exemple, MUSCL avec SSP-RK) afin de réduire la diffusion numérique et de capturer plus précisément les fronts de choc dans les simulations.1

Il est crucial d'étudier et de résoudre l'artefact numérique observé de dépassement de densité (rho\_m \> rho\_jam) au niveau des fronts de choc dans la classe des motos, potentiellement en explorant des fonctions de pression alternatives ou des techniques de limitation physique.1 De plus, un affinement des fonctions physiques au sein du modèle (par exemple,

$ \Pi, g_i, \tau_i $) devrait être exploré, potentiellement basé sur des micro-simulations ou des données comportementales plus fines pour améliorer le réalisme.1 L'identification de l'« artefact numérique (Dépassement $ \rho_m $) » et les recommandations pour l'« Amélioration Numérique (Ordre Supérieur et Chocs) » et l'« Affinement des Fonctions Physiques » démontrent que la modélisation scientifique est un processus intrinsèremment itératif. Même avec un modèle théoriquement solide, les approximations numériques peuvent introduire des écarts ou des artefacts. Cela implique un cycle de raffinement continu où les écarts observés (comme le dépassement de densité) conduisent à des améliorations soit des méthodes numériques, soit du modèle physique sous-jacent, rapprochant ainsi la simulation de la fidélité au monde réel. Ce processus itératif est essentiel pour établir la confiance et la fiabilité dans les modèles prédictifs complexes, reconnaissant que la perfection est un cheminement, pas une destination.

### **8.3 Évolutivité vers les Réseaux Régionaux (MARL) et Intégration avec les Technologies Émergentes (IoT)**

Pour atteindre l'évolutivité régionale, les travaux futurs impliqueront l'implémentation de modèles d'intersection robustes (potentiellement basés sur les données OSM) et l'extension des simulations à des réseaux représentatifs des villes béninoises.1

Une transition vers les paradigmes de l'apprentissage par renforcement multi-agents (MARL), tels que les variantes coopératives Acteur-Critique (par exemple, MAAC-TLC ou MA-SAC), sera essentielle pour gérer des milliers d'intersections hétérogènes à travers les villes.1 Le projet envisage également l'intégration de nouvelles sources de données, telles que les données IoT et les capteurs connectés (par exemple, V2V, V2I), pour fournir des informations en temps réel plus riches et plus granulaires. Cela permettra des stratégies de contrôle plus sophistiquées et potentiellement une transition vers un contrôle plus distribué et centré sur le véhicule.1 La mention explicite de l'« Intégration de données IoT et de capteurs connectés » et du « développement d'approches multi-agents distribuées » dans les orientations futures indique une vision qui dépasse le simple contrôle des feux de signalisation. Cela implique une évolution stratégique vers un écosystème plus large de « ville intelligente ». L'intégration de données IoT granulaires en temps réel fournit les informations d'observation nécessaires, tandis que le MARL apporte l'intelligence distribuée requise pour gérer de vastes réseaux urbains interconnectés. Cela suggère que le projet jette les bases d'un système complet de gestion de la mobilité urbaine capable de s'adapter aux paysages technologiques en évolution (par exemple, les véhicules connectés et autonomes) et de fournir un contrôle plus dynamique et réactif à l'échelle de la ville, contribuant ainsi à un environnement urbain plus intelligent et durable.

## **9\. Conclusion**

Ce travail représente une avancée significative dans la modélisation macroscopique du trafic routier en Afrique de l'Ouest, en particulier à Lagos. Le projet a réussi à formuler et à valider phénoménologiquement une extension multi-classes du modèle Aw-Rascle-Zhang (ARZ) spécifiquement adaptée aux dynamiques uniques du trafic ouest-africain, caractérisées par une hétérogénéité prononcée des véhicules et des comportements de conduite adaptatifs. L'implémentation numérique robuste du modèle, validée par des tests de convergence et de conservation de la masse, constitue une base solide pour les simulations futures.1

Le potentiel d'amélioration quantitative du flux de trafic est substantiel, avec une réduction attendue de 20 à 30% du temps de parcours moyen et une augmentation de 15 à 25% du débit total.1 Au-delà de ses contributions scientifiques, ce projet détient un immense potentiel sociétal et économique pour les villes d'Afrique de l'Ouest, en promettant de réduire les coûts associés à la congestion, d'améliorer la qualité environnementale et d'accroître la qualité de vie des populations.1 Cette initiative est un exemple éloquent du développement de solutions technologiques endogènes, conçues pour répondre aux réalités locales et portées par l'excellence scientifique africaine dans les domaines de pointe de la modélisation mathématique et de l'intelligence artificielle.1

Cependant, la principale limite actuelle réside dans le manque de données de calibration quantitatives, ce qui rend les paramètres du modèle basés sur des estimations plutôt que sur des mesures précises. Pour pleinement réaliser le potentiel du modèle, les étapes futures critiques incluent une collecte de données dédiée et rigoureuse, l'implémentation de schémas numériques d'ordre supérieur pour affiner la précision des simulations, la transition vers des architectures d'apprentissage par renforcement multi-agents (MARL) pour une évolutivité régionale, et l'intégration de technologies émergentes comme l'IoT pour des données en temps réel plus riches.1 Ces avancées permettront de transformer ce modèle en un outil prédictif fiable et un levier stratégique pour une mobilité urbaine plus efficace et durable en Afrique de l'Ouest.

#### **Sources des citations**

1. Josaphat\_tutored\_project.pdf